# -*- coding: utf-8 -*-
"""Proyecto_curso.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1K1myU-x-W5VGg3ZkuEvMn6o13WMNiSGX

# Proyecto Final de Inteligencia Artificial - Diagnóstico de Depresión en Estudiantes
**Descripción**:

Este código implementa un modelo de regresión logística para predecir el riesgo de depresión en estudiantes
universitarios, utilizando un conjunto de datos estructurados que incluye variables como género, ciudad,
profesión, duración del sueño, hábitos alimenticios, antecedentes familiares de enfermedades mentales, entre otros.
El modelo ayuda a identificar patrones asociados con la depresión y proporciona una herramienta para intervenciones
tempranas y personalizadas en el ámbito de la salud mental.

**Fuente del Dataset**:

El conjunto de datos utilizado en este proyecto fue obtenido de Kaggle en el siguiente enlace:
https://www.kaggle.com/datasets/hopesb/student-depression-dataset

**Autoría**:
- López Campillo Francisco Daniel
- Miranda Serrano Jaime Manuel
- Vigi Garduño Marco Alejandro

**Institución**:

Universidad Nacional Autónoma de México, Facultad de Ingeniería
Profesor: M. C. Luis Ochoa Toledo

**Fecha**:

Creado: 20 de noviembre de 2024
Semestre: 2025-1

**Dependencias**:
- Python 3.7+
- Bibliotecas: numpy, pandas, matplotlib, scikit-learn

**Instrucciones de Uso**:
1. Asegúrate de tener el archivo de datos `StudentDepressionDataset.csv` en el mismo directorio que este script.
2. Instala las dependencias necesarias, si no lo están:   pip install numpy pandas matplotlib scikit-learn
3. Ejecuta el código en un entorno compatible (por ejemplo, Jupyter Notebook o Colab).
4. El modelo entrenará, evaluará su precisión y mostrará una curva ROC para interpretar los resultados.

**Entradas**:
- Un archivo CSV con los datos de estudiantes, que incluye variables categóricas y numéricas relacionadas con
factores de riesgo de depresión.

**Salidas**:
- Precisión del modelo en los datos de prueba.
- Gráfico de la curva ROC con el valor de AUC.
- Odds ratios calculados para interpretar el impacto de las variables predictoras.

**Limitaciones**:
- El modelo depende de la calidad de los datos proporcionados.
- No maneja bien interacciones complejas entre variables.

# Importación de bibliotecas necesarias

*   `matplotlib.pyplot` Se usa para graficar la curva característica operativa del receptor (ROC)
*   `numpy` Se usa para calcular la razón de probabilidades (odds ratios)  
*   `pandas` Se usa para manejar el conjunto de datos (dataset)
*   `seaborn` Se usa para visualización de datos mediante gráficos avanzados y personalizados.
*   `joblib` Se usa para guardar y cargar objetos de Python, como modelos entrenados o datasets procesados, de manera eficiente.
*   `LogisticRegression` Lleva a cabo el proceso de regresión lineal
*   `train_test_split` Función que se utiliza para segmentar el conjunto de datos para entrenar y probar el modelo.
accuracy_score Función empleada para medir la precisión del modelo.
*   `roc_curve` Función utilizada para obtener la curva ROC.
*   `roc_auc_score` Función utilizada para obtener el área bajo la curva ROC (AUC).
"""

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
import joblib
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, roc_curve, roc_auc_score, accuracy_score

"""# Lectura del conjunto de datos

Se realiza la lectura del conjunto de datos:
"""

data = pd.read_csv("StudentDepressionDataset.csv")

"""Se muestra el conjunto de datos almacenado:"""

data.head()

"""Se recalca que el dataset fue tomado de Kaggle, del siguiente link:

https://www.kaggle.com/datasets/hopesb/student-depression-dataset

Las características que conforman este conjunto de datos son las siguientes:
- id : Identificador único para cada registro
- Gender : Género
- Age : Edad
- City : Ciudad
- Profession : Profesión
- Academic Pressure : Nivel de presión académica en una escala del 1 al 5
- Work Pressure : Presión relacionada con el trabajo
- CGPA : Promedio Acumulado de Calificaciones
- Study Satisfaction : Nivel de satisfacción relacionada con el estudio en una escala del 1 al 5
- Job Satisfaction: Satisfacción relacionada con el trabajo
- Sleep Duration : Duración promedio del sueño en intervalos categóricos
- Dietary Habits : Hábitos alimenticios (Healthy, Moderate, Unhealthy)
- Degree : Nivel educativo alcanzado o en curso
- Have you ever had suicidal thoughts? : Indica si se ha tenido pensamientos suicidas (Yes, No)
- Work/Study Hours : Número de horas dedidcadas al trabajo o estudio
- Financial Stress : Nivel de estrés financiero en una escala del 1 al 5
- Family History of Mental Illness: Antecedentes familiares de problemas mentales (Yes, No)
- Depression : Variable objetivo (1 para presencia de depresión, 0 para ausencia)

Ya que en la fuente donde se obtuvo este conjunto de datos no se especifican detalles sobre su origen, se asume que es **sintético**.

# Preprocesamiento de datos

Se requiere convertir las variables **categóricas** del dataset en variables **numéricas**:

*   `pd.get_dummies()` utiliza un proceso conocido como codificación one-hot, donde se crean columnas adicionales para cada categoría de una variable.
*   `drop_first = True` es empleado para eliminar una de las columnas obtenidas, lo que evita la colinealidad.
*   `data` Se muestra el dataset modificado.
"""

data = pd.get_dummies(data, columns=['Gender','City','Profession','Sleep Duration','Dietary Habits','Degree','Have you ever had suicidal thoughts ?','Family History of Mental Illness'], drop_first=True)
data

"""Se **separa** a las entradas de las salidas:


*   Se elimina la columna *Depression*.
*   Se considera únicamente a la columna *Depression* como salida.


"""

X = data.drop('Depression',axis=1)
y = data['Depression']

"""Se requiere **eliminar** aquellos campos donde exista un **valor vacío**:


*   Se calcula la cantidad de campos en el dataset previo.
*   Se obtiene un nuevo conjunto de datos de entrada, sin campos con valores vacíos.
*   Se obtiene un nuevo conjunto de datos de salida, haciendo referencia al nuevo conjunto de entrada.
*   Se calcula la cantidad de campos en el dataset modificado.


"""

original_rows = X.shape[0]
X_clean = X.dropna()
y_clean = y[X_clean.index]
cleaned_rows = X_clean.shape[0]

"""Se muestra la comparativa entre el dataset previo y el modificado.

Es mala práctica eliminar datos del espacio muestral de forma arbitraria; en este caso, dado que solo se eliminan 3 registros entre los 27,901, no se genera un sesgo significativo.
"""

print(f"Original number of rows: {original_rows}")
print(f"Number of rows after cleaning: {cleaned_rows}")

"""Se realiza la segmentación de datos para el **entrenamiento** y las **pruebas**:


*   `test_size = 0.3`  Implica que el 30% de los datos en nuestro conjunto se usará para pruebas; de forma implícita, el 70% fr los datos se empleará para el entrenamiento del modelo.
*   `random_state = 42` Se fija una semilla aleatoria que asegura una división de datos reproducible, lo que implica que cada vez que se ejecute este código, se usará la misma división de datos.


"""

X_train, X_test, y_train, y_test = train_test_split(X_clean, y_clean, test_size=0.3, random_state=42)

"""# Entrenamiento del modelo de regresión logística

*   Se genera una **instancia** para la regresión logística.
*   Se utiliza su método `.fit` para entrenar el modelo usando los conjuntos de datos preprocesados para este fin (`X_train`, `y_train`).
"""

log_reg= LogisticRegression()
log_reg.fit(X_train, y_train)

"""En los modelos de regresión logística se obtienen **salidas binarias**.

En este caso, buscamos averiguar si los estudiantes, codificados como registros en nuestro dataset, **tienen** o **no tienen** depresión (*variable dependiente*), en función de las características definidas (*variables independientes*) en el conjunto de datos, como género, ciudad, profesión, duración del sueño, nivel de estrés o satisfacción relacionado con el estudio, entre otras.

En términos simples, se modela la probabilidad (en escala logarítmica) de que de la variable dependiente sea **cierta**, como una combinación lineal de las variables independientes. Para lograr este fin, se utiliza un método denominado como **Estimación de Máxima Verosimilitud**, a través de `LogisticRegression()`, que estima los parámetros del modelo que se usarán para realizar predicciones posteriormente.

Para más información, consultar la documentación de scikit-learn:

https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html

# Generación de predicciones con el modelo entrenado

Se utiliza la instancia del modelo entrenado para predecir la **salida del conjunto de datos apartado para la prueba** (30% del dataset original).
"""

y_pred = log_reg.predict(X_test)
y_pred

"""Se multiplica cada una de las características de la entrada (codificada en valores numéricos) por sus parámetros correspondientes calculados en el entrenamiento, haciendo una sumatoria de los productos.

El resultado de esta suma se emplea para llevar a cabo la transformación con la función sigmoide, de manera que se obtiene una probabilidad:
$$P(depresión)=\frac{1}{1+e^{-z}}$$
Donde z es la sumatoria antes mencionada.

Los resultados no son directamente `True` o `False`, como vimos en la sección de generación de predicciones. Los resultados reales se presentan como probabilidades, que al superar 0.5 se transforman en `True`:
"""

y_pred_proba = log_reg.predict_proba(X_test)[:,1]
y_pred_proba

"""Tras calcular los parámetros en el entrenamiento, se les puede aplicar la función exponencial para poder interpretar el impacto que posee cada una de las características descritas en el conjunto de datos.


"""

odds_ratios = np.exp(log_reg.coef_)
odds_ratios

"""Para reducir el análisis de las 111 columnas, seleccionaremos aquellas que tengan una influencia de al menos 10% de forma positiva o negativa en el resultado de las predicciones.
Si restamos uno a cada valor, obtenemos el porcentaje de aumento (si el signo es positivo) o decremento (si el signo es negativo) en la probabilidad de depresión del estudiante, por unidad de aumento en el dato correspondiente.

- Age : 0.8834 - 1 = -11.66%
- Academic Pressure = 2.4433 - 1 = 144.33%
- CGPA : 0.8814 - 1 = -11.86%
- Study Satisfaction : 0.7136 - 1 = -28.64%
- Work/Study Hours : 1.1123 - 1 = 11.23%
- Financial Stress : 1.767 - 1 = 76.7%
- Degree_B.Tech : 1.1930 - 1 = 19.3%
- Have you ever had suicidal thoughts ?_Yes = 1.7521 - 1 = 75.21%

De esta forma, podemos interpretar que aquellos estudiantes con presión académica alta, mayor número de horas de estudio, estrés financiero alto, que hayan tenido pensamientos suicidas o que posean una carrera en tecnología son **más propensos a tener depresión**, según nuestro modelo.

Por otra parte, aquellos que son mayores, que tienen mayor promedio de calificaciones o que tienen un nivel de satisfacción del estudio mayor son **menos propensos a tener depresión**, según nuestro modelo.

Esto nos hace cuestionar: ¿Qué tan confiables son estos datos?

Esa pregunta se responderá en la siguiente sección.

# Evaluación del modelo

Considerando los siguientes parámetros:

- **Verdaderos Positivos (TP)**: Casos `True` correctamente clasificados.
- **Verdaderos Negativos (TN)**: Casos `False` correctamente clasificados.
- **Falsos Positivos (FP)**: Casos `True` incorrectamente clasificados.
- **Falsos Negativos (FN)**: Casos `False` incorrectamente clasificados.

Se puede describir de forma breve a las métricas utilizadas para la evaluación del modelo:

*   Utilizamos `confusion_matrix()`, lo que nos proporciona la matriz de TN, FP, FN y TN.

*   Utilizamos `precision_score()`, lo que mide la **precisión** del modelo (porcentaje de predicciones positivas que fueron correctas):
$$Precisión=\frac{TP}{TP\, +\, FP}$$

*   Utilizamos `recall_score()`, lo que mide la **sensibilidad** del modelo (porcentaje de predicciones positivas que fueron correctas):
$$Sensibilidad=\frac{TP}{TP\, +\, FN}$$

*   Utilizamos `f1_score()`, lo que mide la **media armónica** entre la **precisión** y la **sensibilidad** del modelo (balancea ambas, ya que considera tanto los falsos positivos como los falsos negativos):
$$Media\, armónica=2*\frac{Precisión*Sensibilidad}{Precisión+Sensibilidad}$$

*   Utilizamos `accuracy_score()`, lo que mide la **exactitud** del modelo (análisis general entre los tipos de errores, ya que no los distingue):
$$Exactitud=\frac{TP\, +\, TN}{TP\, +\, TN\, +\, FP\, +\, FN}$$
"""

cm = confusion_matrix(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
accuracy = accuracy_score(y_test, y_pred)

"""Para representar los datos de manera concentrada, se genera una matriz de las métricas obtenidas (Data Frame):"""

# Crear un DataFrame con las métricas
metrics = {
    "Métrica": ["Falsos Positivos", "Falsos Negativos", "Precisión", "Recall", "F1-score", "Exactitud"],
    "Valor": [cm[0][1], cm[1][0], precision, recall, f1, accuracy]  # cm[0][1] es Falsos Positivos, cm[1][0] es Falsos Negativos
}
results_df = pd.DataFrame(metrics)
print(results_df)

"""**Interpretación de los resultados**


0.   `FP = 944` Implica que se encontraron 944 casos que el modelo clasificó erróneamente como positivos.
1.   `FN = 655` Implica que se encontraron 655 casos que el modelo clasificó erróneamente como negativos.
2.   `precision = 0.817655` Implica que, de todas las predicciones positivas hechas por el modelo, el 81.77% fueron correctas. Esto indica que el modelo es **confiable** cuando **predice** que un caso es **positivo**, sin considerar qué tan bien identifica todos los casos positivos.
3.   `recall = 0.865998` En este caso, de todos los casos que realmente eran positivos, el modelo identificó correctamente el 86.60%. A diferencia de la métrica anterior, este porcentaje indidca que el modelo tiene un **buen desempeño** identificando **todos los casos positivos**.
4.   `f1 = 0.841133` El modelo tiene un buen balance (84.11%) entre identificar correctamente los positivos y minimizar los falsos positivos.
5.   `accuracy = 0.808961` Implica que el **porcentaje total** de predicciones correctas realizadas por el modelo, incluyendo tanto positivos como negativos, es de 80.90%. En general, una exactitud por encima del 80% es **buena**.

Como mencionamos anteriormente, los parámetros TN, FP, FN y TP fueron obtenidos de la matriz de confusión, que se presenta directamente a continuación:
"""

print(cm)

"""Donde:
*   TN = 2538
*   FP = 944
*   FN = 655
*   TP = 4233

El mapa de calor presentado a continuación puede ayudar a comprender mejor los resultados:
"""

sns.heatmap(cm)

"""Dada en la función `cm = confusion_matrix(y_test, y_pred)` se considera la siguiente estructura de la matriz de confusión:
$$
\begin{bmatrix}
    \text{TN} & \text{FP} \\
    \text{FN} & \text{TP}
\end{bmatrix}
$$
Conforme la sección se acerca más al blanco, se destaca la proporción dado el volumen total del conjunto de datos de prueba.
Por esta razón, al visualizar el cuadrante superior derecho, y el cuadrante inferior izquierdo, ambos con un color negro, se interpreta que existe una menor proporción de error.


---

La siguiente métrica que se emplea para evaluar el modelo se denomina como la curva característica operativa del receptor. La **curva ROC** es una representación gráfica de la **sensibilidad** del modelo (**recall** o True Positive Rate, **TPR**) vs la **especificidad** (también conocida como True Negative Rate, **TNR**). Es una herramienta que evalúa el desempeño de un modelo de clasificación binaria.

Recordando la definición de la sensibilidad:
$$Sensibilidad=\frac{TP}{TP\, +\, FN}$$

Considerando la definición de la especificidad:
$$Especificidad=\frac{FP}{FP\, +\, TN}$$
"""

fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)
auc = roc_auc_score(y_test, y_pred_proba)

"""Se utilizan las funciones de la biblioteca `matplotlib.pyplot` para la representación de la curva:"""
"""
plt.plot(fpr, tpr, label=f'AUC = {auc:.2f}')
plt.plot([0,1],[0,1],linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend(loc = 'lower right')
plt.show()
"""
"""*   La línea azul es la curva ROC del modelo. Como se puede apreciar, se sitúa cerca del punto (0,1), lo que indica una **alta sensibilidad** y una **baja tasa de falsos positivos**.
*   Esta cercanía a la esquina superior izquierda del modelo se puede caracterizar como el área bajo la curva de la curva ROC (**AUC**), que en este caso es igual a 0.89. Como se mencionó anteriormente, esto indica un buen desempeño del modelo.
*   La línea diagonal naranja representa a un modelo aleatorio que no tiene capacidad predictiva, con un AUC de 0.5. El área bajo la curva ROC se delimita con esta línea.

## **Ejemplo 1:** Predicción realizada.
Estudiante hombre de 25 años con una presion academica de 3, promedio de 8.0, 6 horas de escuela/trabajo al dia, presion laboral de 0 (NO TRABAJA), satisfaccion de estudios de 3, estres financiero de 4, sin antecedentes familiares, con pensamientos suicidas, durmiendo menos de 5hrs, y teniendo habitos de dieta moderados:
"""

# Creamos un DataFrame vacío con las columnas esperadas
nuevo_estudiante_completo = pd.DataFrame(columns=X_clean.columns)

# Inicializamos todas las columnas en 0
nuevo_estudiante_completo.loc[0] = 0

# Datos básicos del alumno
nuevo_estudiante_completo.loc[0, 'Gender_Male'] = 1  # Género: Hombre=1, Mujer=0
nuevo_estudiante_completo.loc[0, 'Age'] = 25  # Edad en años

# Factores académicos del alumno
nuevo_estudiante_completo.loc[0, 'Academic Pressure'] = 3  # Presión académica: Escala del 1-5
nuevo_estudiante_completo.loc[0, 'CGPA'] = 8.0  # Promedio acumulado de calificaciones
nuevo_estudiante_completo.loc[0, 'Work/Study Hours'] = 6  # Horas de trabajo o estudio al día

# Factores laborales del alumno
nuevo_estudiante_completo.loc[0, 'Work Pressure'] = 0  # Presión laboral: Escala del 1-5

# Salud mental del alumno
nuevo_estudiante_completo.loc[0, 'Study Satisfaction'] = 3  # Satisfacción en los estudios: Escala del 1-5
nuevo_estudiante_completo.loc[0, 'Financial Stress'] = 4  # Estrés financiero: Escala del 1-5
nuevo_estudiante_completo.loc[0, 'Family History of Mental Illness_Yes'] = 0  # Antecedentes familiares: Sí=1, No=0
nuevo_estudiante_completo.loc[0, 'Have you ever had suicidal thoughts ?_Yes'] = 1  # Pensamientos suicidas: Sí=1, No=0

# Hábitos de sueño del alumno
nuevo_estudiante_completo.loc[0, 'Sleep Duration_7-8 hours'] = 0  # Duración del sueño: 7-8 horas=1
nuevo_estudiante_completo.loc[0, 'Sleep Duration_Less than 5 hours'] = 1  # Menos de 5 horas=1
nuevo_estudiante_completo.loc[0, 'Sleep Duration_More than 8 hours'] = 0  # Más de 8 horas=1

# Hábitos alimenticios del alumno
nuevo_estudiante_completo.loc[0, 'Dietary Habits_Others'] = 0  # Hábitos no categorizados
nuevo_estudiante_completo.loc[0, 'Dietary Habits_Moderate'] = 1  # Moderados=1
nuevo_estudiante_completo.loc[0, 'Dietary Habits_Unhealthy'] = 0  # Poco saludables=0

# Profesión del alumno
nuevo_estudiante_completo.loc[0, 'Profession_Student'] = 1  # Estudiante=1

# Nos aseguramos de que las columnas coincidan exactamente
nuevo_estudiante_completo = nuevo_estudiante_completo.fillna(0)

# Eliminamos columnas no reconocidas
extra_cols = [col for col in nuevo_estudiante_completo.columns if col not in X_clean.columns]
if extra_cols:
    print(f"Eliminando columnas no reconocidas: {extra_cols}")
    nuevo_estudiante_completo.drop(columns=extra_cols, inplace=True)

# Realizamos la predicción en base al estudiante de ejemplo
prediccion = log_reg.predict(nuevo_estudiante_completo)
probabilidad = log_reg.predict_proba(nuevo_estudiante_completo)[0][1]

# Mostramos el resultados
if prediccion[0] == 1:
    print(f"Alto riesgo de depresión (Probabilidad: {probabilidad:.2f})")
else:
    print(f"Bajo riesgo de depresión (Probabilidad: {probabilidad:.2f})")

"""## **Ejemplo 2:** Predicción realizada.
Estudiante mujer de 21 años con una presion academica de 4, promedio de 9.0, 7 horas de escuela/trabajo al dia, presion laboral de 2, satisfaccion de estudios de 4, estres financiero de 2, sin antecedentes familiares, sin pensamientos suicidas, durmiendo menos de entre 7 y 8hrs, y teniendo buenos habitos de dieta:
"""

# Creamos un DataFrame vacío con las columnas esperadas
nuevo_estudiante_completo = pd.DataFrame(columns=X_clean.columns)

# Inicializamos todas las columnas en 0
nuevo_estudiante_completo.loc[0] = 0

# Datos básicos del alumno
nuevo_estudiante_completo.loc[0, 'Gender_Male'] = 0  # Género: Hombre=1, Mujer=0
nuevo_estudiante_completo.loc[0, 'Age'] = 21  # Edad en años

# Factores académicos del alumno
nuevo_estudiante_completo.loc[0, 'Academic Pressure'] = 4  # Presión académica: Escala del 1-5
nuevo_estudiante_completo.loc[0, 'CGPA'] = 9.0  # Promedio acumulado de calificaciones
nuevo_estudiante_completo.loc[0, 'Work/Study Hours'] = 7  # Horas de trabajo o estudio al día

# Factores laborales del alumno
nuevo_estudiante_completo.loc[0, 'Work Pressure'] = 2  # Presión laboral: Escala del 1-5

# Salud mental del alumno
nuevo_estudiante_completo.loc[0, 'Study Satisfaction'] = 4  # Satisfacción en los estudios: Escala del 1-5
nuevo_estudiante_completo.loc[0, 'Financial Stress'] = 2  # Estrés financiero: Escala del 1-5
nuevo_estudiante_completo.loc[0, 'Family History of Mental Illness_Yes'] = 0  # Antecedentes familiares: Sí=1, No=0
nuevo_estudiante_completo.loc[0, 'Have you ever had suicidal thoughts ?_Yes'] = 0  # Pensamientos suicidas: Sí=1, No=0

# Hábitos de sueño del alumno
nuevo_estudiante_completo.loc[0, 'Sleep Duration_7-8 hours'] = 1  # Duración del sueño: 7-8 horas=1
nuevo_estudiante_completo.loc[0, 'Sleep Duration_Less than 5 hours'] = 0  # Menos de 5 horas=1
nuevo_estudiante_completo.loc[0, 'Sleep Duration_More than 8 hours'] = 0  # Más de 8 horas=1

# Hábitos alimenticios del alumno
nuevo_estudiante_completo.loc[0, 'Dietary Habits_Others'] = 1  # Hábitos no categorizados
nuevo_estudiante_completo.loc[0, 'Dietary Habits_Moderate'] = 0  # Moderados=1
nuevo_estudiante_completo.loc[0, 'Dietary Habits_Unhealthy'] = 0  # Poco saludables=0

# Profesión del alumno
nuevo_estudiante_completo.loc[0, 'Profession_Student'] = 1  # Estudiante=1

# Nos aseguramos de que las columnas coincidan exactamente
nuevo_estudiante_completo = nuevo_estudiante_completo.fillna(0)

# Eliminamos columnas no reconocidas
extra_cols = [col for col in nuevo_estudiante_completo.columns if col not in X_clean.columns]
if extra_cols:
    print(f"Eliminando columnas no reconocidas: {extra_cols}")
    nuevo_estudiante_completo.drop(columns=extra_cols, inplace=True)

# Realizamos la predicción en base al estudiante de ejemplo
prediccion = log_reg.predict(nuevo_estudiante_completo)
probabilidad = log_reg.predict_proba(nuevo_estudiante_completo)[0][1]

# Mostramos el resultados
if prediccion[0] == 1:
    print(f"Alto riesgo de depresión (Probabilidad: {probabilidad:.2f})")
else:
    print(f"Bajo riesgo de depresión (Probabilidad: {probabilidad:.2f})")

"""## **Ejemplo 3:** Predicción realizada.
Estudiante hombre de 23 años con una presion academica de 2, promedio de 9.0, 5 horas de escuela/trabajo al dia, presion laboral de 0 (NO TRABAJA), satisfaccion de estudios de 5, estres financiero de 1, sin antecedentes familiares, sin pensamientos suicidas, durmiendo entre 7 y 8hrs, y teniendo habitos de dieta moderados:
"""

# Creamos un DataFrame vacío con las columnas esperadas
nuevo_estudiante_completo = pd.DataFrame(columns=X_clean.columns)

# Inicializamos todas las columnas en 0
nuevo_estudiante_completo.loc[0] = 0

# Datos básicos del alumno
nuevo_estudiante_completo.loc[0, 'Gender_Male'] = 1  # Género: Hombre=1, Mujer=0
nuevo_estudiante_completo.loc[0, 'Age'] = 23  # Edad en años

# Factores académicos del alumno
nuevo_estudiante_completo.loc[0, 'Academic Pressure'] = 2  # Presión académica: Escala del 1-5
nuevo_estudiante_completo.loc[0, 'CGPA'] = 9.0  # Promedio acumulado de calificaciones
nuevo_estudiante_completo.loc[0, 'Work/Study Hours'] = 5  # Horas de trabajo o estudio al día

# Factores laborales del alumno
nuevo_estudiante_completo.loc[0, 'Work Pressure'] = 0  # Presión laboral: Escala del 1-5

# Salud mental del alumno
nuevo_estudiante_completo.loc[0, 'Study Satisfaction'] = 5  # Satisfacción en los estudios: Escala del 1-5
nuevo_estudiante_completo.loc[0, 'Financial Stress'] = 1  # Estrés financiero: Escala del 1-5
nuevo_estudiante_completo.loc[0, 'Family History of Mental Illness_Yes'] = 0  # Antecedentes familiares: Sí=1, No=0
nuevo_estudiante_completo.loc[0, 'Have you ever had suicidal thoughts ?_Yes'] = 0  # Pensamientos suicidas: Sí=1, No=0

# Hábitos de sueño del alumno
nuevo_estudiante_completo.loc[0, 'Sleep Duration_7-8 hours'] = 1  # Duración del sueño: 7-8 horas=1
nuevo_estudiante_completo.loc[0, 'Sleep Duration_Less than 5 hours'] = 0  # Menos de 5 horas=1
nuevo_estudiante_completo.loc[0, 'Sleep Duration_More than 8 hours'] = 0  # Más de 8 horas=1

# Hábitos alimenticios del alumno
nuevo_estudiante_completo.loc[0, 'Dietary Habits_Others'] = 0  # Hábitos no categorizados
nuevo_estudiante_completo.loc[0, 'Dietary Habits_Moderate'] = 1  # Moderados=1
nuevo_estudiante_completo.loc[0, 'Dietary Habits_Unhealthy'] = 0  # Poco saludables=0

# Profesión del alumno
nuevo_estudiante_completo.loc[0, 'Profession_Student'] = 1  # Estudiante=1

# Nos aseguramos de que las columnas coincidan exactamente
nuevo_estudiante_completo = nuevo_estudiante_completo.fillna(0)

# Eliminamos columnas no reconocidas
extra_cols = [col for col in nuevo_estudiante_completo.columns if col not in X_clean.columns]
if extra_cols:
    print(f"Eliminando columnas no reconocidas: {extra_cols}")
    nuevo_estudiante_completo.drop(columns=extra_cols, inplace=True)

# Realizamos la predicción en base al estudiante de ejemplo
prediccion = log_reg.predict(nuevo_estudiante_completo)
probabilidad = log_reg.predict_proba(nuevo_estudiante_completo)[0][1]

# Mostramos el resultados
if prediccion[0] == 1:
    print(f"Alto riesgo de depresión (Probabilidad: {probabilidad:.2f})")
else:
    print(f"Bajo riesgo de depresión (Probabilidad: {probabilidad:.2f})")

"""# Realizamos la exportación para que se almacene el modelo realizado y poderlo ejecutar en el formulario de forma pública."""

joblib.dump(log_reg, 'proyecto_curso.pkl')

"""# Conclusión

El modelo que desarrollamos nos ayudó a identificar casos de estudiantes con posibles problemas de depresión, lo que representó un paso importante para abordar un tema tan delicado y relevante lo cual a lo largo del proyecto analizamos diferentes métricas para evaluar su desempeño, como la curva ROC, que mostró resultados positivos al acercarse al punto ideal, esto nos ayuda a vlidar que nuestro modelo tiene una buena capacidad para distinguir entre estudiantes que podrían estar enfrentando dificultades emocionales y aquellos que no, este logro nos dejó satisfechos, aunque también somos conscientes de que aún hay áreas donde podemos mejorar, como reducir los casos en los que se generan falsos positivos, creemos que con más ajustes el modelo puede ser aún más efectivo, lo que refuerza nuestra confianza en que la inteligencia artificial puede ser una herramienta poderosa para abordar temas de salud mental, especialmente en un grupo vulnerable como lo somos los estudiantes.

Durante el desarrollo, también aprendimos que hay muchas oportunidades para seguir mejorando, podríamos probar otros enfoques o combinar este modelo con más datos que lo enriquezcan y aumenten su capacidad de predicción, además nos gustaría probarlo en diferentes contextos, tal vez con estudiantes de otras edades o instituciones, para entender mejor cómo se adapta y qué ajustes podrían hacerlo más útil por lo que en general este proyecto nos permitió no solo conocer el potencial de la inteligencia artificial en la salud, sino también reflexionar sobre cómo la tecnología puede ser una herramienta clave para mejorar la vida de las personas, por lo que con más trabajo y dedicación, este tipo de herramientas puede marcar una gran diferencia en la detección, prevención y tratamiento de problemas que afectan tanto a la mente como al bienestar de los estudiantes.
"""